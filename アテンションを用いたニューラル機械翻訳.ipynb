{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "アテンションを用いたニューラル機械翻訳",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syusuke9999/Sequence-to-Sequence-/blob/main/%E3%82%A2%E3%83%86%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_qNSzzyaCbD"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jmjh290raIky"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# アテンションを用いたニューラル機械翻訳"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tudzcncJXetB"
      },
      "source": [
        "Note: これらのドキュメントは私たちTensorFlowコミュニティが翻訳したものです。コミュニティによる 翻訳は**ベストエフォート**であるため、この翻訳が正確であることや[英語の公式ドキュメント](https://www.tensorflow.org/?hl=en)の 最新の状態を反映したものであることを保証することはできません。 この翻訳の品質を向上させるためのご意見をお持ちの方は、GitHubリポジトリ[tensorflow/docs](https://github.com/tensorflow/docs)にプルリクエストをお送りください。 コミュニティによる翻訳やレビューに参加していただける方は、 [docs-ja@tensorflow.org メーリングリスト](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ja)にご連絡ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tutorials/text/nmt_with_attention.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/text/nmt_with_attention.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tutorials/text/nmt_with_attention.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EKgOgLsSOrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583b992d-36ae-4499-fc19-109a0d67140a"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "import unicodedata\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from matplotlib import font_manager\n",
        "import numpy as np\n",
        "import numpy as numpy\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9EqFqMMqWyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef382cd7-6325-4bbb-f184-1782cbfac543"
      },
      "source": [
        "!apt-get -y install fonts-ipafont-gothic\n",
        "!apt autoremove\n",
        "plt.rcParams[\"font.family\"]='IPAGothic'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-ipafont-gothic is already the newest version (00303-18ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwtNgENbx2g"
      },
      "source": [
        "このノートブックでは、英語から日本語への翻訳を行う Sequence to Sequence (seq2seq) モデルを訓練します。このチュートリアルは、 Sequence to Sequence モデルの知識があることを前提にした上級編のサンプルです。\n",
        "\n",
        "このノートブックのモデルを訓練すると、_\"are you still at home?\"_  のような英語の文を入力して、和訳：  _\"まだ家にいるの？\"_  を得ることができます。\n",
        "\n",
        "この翻訳品質はおもちゃとしてはそれなりのものですが、生成されたアテンションの図表の方が面白いかもしれません。これは、翻訳時にモデルが入力文のどの部分に注目しているかを表しています。\n",
        "\n",
        "<img src=\"https://tensorflow.org/images/spanish-english.png\" alt=\"spanish-english attention plot\">\n",
        "\n",
        "Note: このサンプルは P100 GPU 1基で実行した場合に約 10 分かかります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcJnYmo2uPfx"
      },
      "source": [
        "!rm -r /root/.cache/matplotlib/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjR6LvFYKC4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45bfcd3e-1236-4d1f-dbf6-16b4eee24e02"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr  2 13:08:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y3CUrkCNDPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73168136-26c0-448c-d502-e6dbb607a494"
      },
      "source": [
        "# 形態素分析ライブラリーMeCab と 辞書(mecab-ipadic-NEologd)のインストール \n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab\n",
        "!git clone --depth=1 -b v0.0.7 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n\n",
        "!echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"\n",
        "!pip install mecab-python3\n",
        "!sudo apt autoremove\n",
        "# シンボリックリンクによるエラー回避\n",
        "!ln -s /etc/mecabrc /usr/local/etc/mecabrc"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libmecab-dev is already the newest version (0.996-5).\n",
            "mecab is already the newest version (0.996-5).\n",
            "mecab-ipadic-utf8 is already the newest version (2.7.0-20070801+main-1).\n",
            "python-mecab is already the newest version (0.99.6-2).\n",
            "curl is already the newest version (7.58.0-2ubuntu3.16).\n",
            "file is already the newest version (1:5.32-2ubuntu0.4).\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.9).\n",
            "sudo is already the newest version (1.8.21p2-3ubuntu1.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "fatal: destination path 'mecab-ipadic-neologd' already exists and is not an empty directory.\n",
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : Check the existance of libraries\n",
            "[install-mecab-ipadic-NEologd] :     find => ok\n",
            "[install-mecab-ipadic-NEologd] :     sort => ok\n",
            "[install-mecab-ipadic-NEologd] :     head => ok\n",
            "[install-mecab-ipadic-NEologd] :     cut => ok\n",
            "[install-mecab-ipadic-NEologd] :     egrep => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab-config => ok\n",
            "[install-mecab-ipadic-NEologd] :     make => ok\n",
            "[install-mecab-ipadic-NEologd] :     curl => ok\n",
            "[install-mecab-ipadic-NEologd] :     sed => ok\n",
            "[install-mecab-ipadic-NEologd] :     cat => ok\n",
            "[install-mecab-ipadic-NEologd] :     diff => ok\n",
            "[install-mecab-ipadic-NEologd] :     tar => ok\n",
            "[install-mecab-ipadic-NEologd] :     unxz => ok\n",
            "[install-mecab-ipadic-NEologd] :     xargs => ok\n",
            "[install-mecab-ipadic-NEologd] :     grep => ok\n",
            "[install-mecab-ipadic-NEologd] :     iconv => ok\n",
            "[install-mecab-ipadic-NEologd] :     patch => ok\n",
            "[install-mecab-ipadic-NEologd] :     which => ok\n",
            "[install-mecab-ipadic-NEologd] :     file => ok\n",
            "[install-mecab-ipadic-NEologd] :     openssl => ok\n",
            "[install-mecab-ipadic-NEologd] :     awk => ok\n",
            "\n",
            "fatal: ambiguous argument 'refs/heads/master': unknown revision or path not in the working tree.\n",
            "Use '--' to separate paths from revisions, like this:\n",
            "'git <command> [<revision>...] -- [<file>...]'\n",
            "mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd: line 348: [: =: unary operator expected\n",
            "[install-mecab-ipadic-NEologd] : Get the newest updated information using git\n",
            "fatal: ambiguous argument 'origin/master': unknown revision or path not in the working tree.\n",
            "Use '--' to separate paths from revisions, like this:\n",
            "'git <command> [<revision>...] -- [<file>...]'\n",
            "/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "ln: failed to create symbolic link '/usr/local/etc/mecabrc': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdUASWIhkMOg"
      },
      "source": [
        "import MeCab\n",
        "tokenizer = MeCab.Tagger('/usr/local/etc/mecabrc')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToJupnirSidT"
      },
      "source": [
        "def is_japanese(string):\n",
        "    for ch in string:\n",
        "        name = unicodedata.name(ch) \n",
        "        if \"CJK UNIFIED\" in name \\\n",
        "        or \"HIRAGANA\" in name \\\n",
        "        or \"KATAKANA\" in name:\n",
        "            return True\n",
        "    return False\n",
        "# ユニコードファイルを ascii に変換\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFKC', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w)\n",
        "    if is_japanese(w) is True:\n",
        "        w = re.sub(r\"(\\d{1,3})(,)(\\d{3})\", r'\\1\\3', w)\n",
        "        w = re.sub(r\"([？。！、])\", r\" \\1 \", w)\n",
        "        # Mecabを使用して、wとして渡されたテキストを形態素解析して分かち書きしたものを返す。\n",
        "        mecab = MeCab.Tagger (\"-Owakati\")\n",
        "        w = mecab.parse (w)\n",
        "    w = w.lower()\n",
        "    w = re.sub(r\"(\\d{1,3})(,)(\\d{3})\", r'\\1\\3', w)\n",
        "    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
        "    w = w.lower()\n",
        "    ''.join(w).splitlines()\n",
        "    # 文の開始と終了のトークンを付加\n",
        "    # モデルが予測をいつ開始し、いつ終了すれば良いかを知らせるため\n",
        "    w = w.rstrip().strip()\n",
        "    w.replace('\\r','')\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjf_mjVxSvwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a47a16-10e4-4a6c-fa9d-631dcfade861"
      },
      "source": [
        "en_sentence = \"It's all you can drink for 2 hours for 2,500 yen.\"\n",
        "jp_sentence = \"2時間2,500円で飲み放題。\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(jp_sentence))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> it's all you can drink for 2 hours for 2500 yen . <end>\n",
            "<start> 2 時間 2500 円 で 飲み 放題 。 <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAEKJmvdSWzZ"
      },
      "source": [
        "# 1. アクセント記号を除去\n",
        "# 2. 文をクリーニング\n",
        "# 3. [ENGLISH, JAPANESE] の形で単語のペアを返す\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    word_pare = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "    return zip(*word_pare)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイルパスの指定\n",
        "path_to_file = tf.keras.utils.get_file('/content/drive/MyDrive/eng_jpn/eng_jpn.txt', origin='https://storage.googleapis.com/eng_jpn_corpus/eng_jpn.txt')"
      ],
      "metadata": {
        "id": "edU11pzu8ZWG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXYn17MzTGHK"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "    return tensor, lang_tokenizer"
      ],
      "metadata": {
        "id": "4u_gdmPN8qXq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en, jp = create_dataset(path_to_file, 500)\n",
        "print(en[-1])\n",
        "print(jp[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLSORtL_8icB",
        "outputId": "6204f259-4845-4c63-c007-c062b4ca4f72"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> i mean it ! <end>\n",
            "<start> 本気 だ よ 。 <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "    # クリーニングされた入力と出力のペアを生成\n",
        "    inp_lang, targ_lang = create_dataset(path, num_examples)\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOi42V79Ydlr"
      },
      "source": [
        "### 実験を速くするためデータセットのサイズを制限（オプション）\n",
        "\n",
        "100,000 を超える文のデータセットを使って訓練するには長い時間がかかります。訓練を速くするため、データセットのサイズを 30,000 に制限することができます（もちろん、データが少なければ翻訳の品質は低下します）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfodePkj3jEa"
      },
      "source": [
        "## データセットのダウンロードと準備\n",
        "\n",
        "ここでは、http://www.manythings.org/anki/ で提供されている言語データセットを使用します。このデータセットには、次のような書式の言語翻訳ペアが含まれています。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### May I borrow this book?\tこの本を借りてもいいですか？\n",
        "\n",
        "\n",
        "\n",
        "さまざまな言語が用意されていますが、ここでは英語－日本語のデータセットを使用します。利便性を考えてこのデータセットは Google Cloud 上に用意してありますが、ご自分でダウンロードすることも可能です。データセットをダウンロードしたあと、データを準備するために下記のようないくつかの手順を実行します。\n",
        "\n",
        "1. それぞれの文ごとに、*開始* と *終了* のトークンを付加する\n",
        "2. 特殊文字を除去して文をきれいにする\n",
        "3. 単語インデックスと逆単語インデックス（単語 → id と id → 単語のマッピングを行うディクショナリ）を作成する\n",
        "4. 最大長にあわせて各文をパディングする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnxC7q-j3jFD"
      },
      "source": [
        "# このサイズのデータセットで実験\n",
        "checkpoint_path = '/content/drive/MyDrive/Checkpoints/'\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx6V7J1qrEo5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "318505de-4fcd-4813-98c9-4c9c2e09da1b"
      },
      "source": [
        "'''\n",
        "# loading\n",
        "input_tensor_train = numpy.load(checkpoint_path + 'Tokenizer/input_tensor_train.npy')\n",
        "input_tensor_val = numpy.load(checkpoint_path + 'Tokenizer/input_tensor_val.npy')\n",
        "target_tensor_train = numpy.load(checkpoint_path + 'Tokenizer/target_tensor_train.npy')\n",
        "target_tensor_val= numpy.load(checkpoint_path + 'Tokenizer/target_tensor_val.npy')\n",
        "input_tensor = numpy.load(checkpoint_path + 'Tokenizer/input_tensor.npy')\n",
        "target_tensor = numpy.load(checkpoint_path + 'Tokenizer/target_tensor.npy')\n",
        "with open(checkpoint_path + 'Tokenizer/inp_lang.pickle', 'rb') as handle:\n",
        "    inp_lang = pickle.load(handle)\n",
        "with open(checkpoint_path + 'Tokenizer/targ_lang.pickle', 'rb') as handle:\n",
        "    targ_lang = pickle.load(handle)\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# loading\\ninput_tensor_train = numpy.load(checkpoint_path + 'Tokenizer/input_tensor_train.npy')\\ninput_tensor_val = numpy.load(checkpoint_path + 'Tokenizer/input_tensor_val.npy')\\ntarget_tensor_train = numpy.load(checkpoint_path + 'Tokenizer/target_tensor_train.npy')\\ntarget_tensor_val= numpy.load(checkpoint_path + 'Tokenizer/target_tensor_val.npy')\\ninput_tensor = numpy.load(checkpoint_path + 'Tokenizer/input_tensor.npy')\\ntarget_tensor = numpy.load(checkpoint_path + 'Tokenizer/target_tensor.npy')\\nwith open(checkpoint_path + 'Tokenizer/inp_lang.pickle', 'rb') as handle:\\n    inp_lang = pickle.load(handle)\\nwith open(checkpoint_path + 'Tokenizer/targ_lang.pickle', 'rb') as handle:\\n    targ_lang = pickle.load(handle)\\nmax_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kot-K3aMgNtC"
      },
      "source": [
        "**再実行の際はここから**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16eqlT3AFF4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27494780-fa2e-4ba6-e65a-48b3e1126b2f"
      },
      "source": [
        "# 80-20で分割を行い、訓練用と検証用のデータセットを作成\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, shuffle=True, test_size=0.2)\n",
        "\n",
        "# 長さを表示\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53548 53548 13387 13387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfRDTX31rXsE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "7812fc97-5f12-424d-ac15-319b755aff93"
      },
      "source": [
        "'''\n",
        "# saving\n",
        "numpy.save(checkpoint_path + 'Tokenizer/input_tensor_train.npy',input_tensor_train)\n",
        "numpy.save(checkpoint_path + 'Tokenizer/input_tensor_val.npy',input_tensor_val)\n",
        "numpy.save(checkpoint_path + 'Tokenizer/target_tensor_train.npy',target_tensor_train)\n",
        "numpy.save(checkpoint_path + 'Tokenizer/target_tensor_val.npy',target_tensor_val)\n",
        "numpy.save(checkpoint_path + 'Tokenizer/input_tensor.npy',input_tensor)\n",
        "numpy.save(checkpoint_path + 'Tokenizer/target_tensor.npy',target_tensor)\n",
        "with open(checkpoint_path +  'Tokenizer/inp_lang.pickle', 'wb') as handle:\n",
        "    pickle.dump(inp_lang, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open(checkpoint_path + 'Tokenizer/targ_lang.pickle', 'wb') as handle:\n",
        "    pickle.dump(targ_lang, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# saving\\nnumpy.save(checkpoint_path + 'Tokenizer/input_tensor_train.npy',input_tensor_train)\\nnumpy.save(checkpoint_path + 'Tokenizer/input_tensor_val.npy',input_tensor_val)\\nnumpy.save(checkpoint_path + 'Tokenizer/target_tensor_train.npy',target_tensor_train)\\nnumpy.save(checkpoint_path + 'Tokenizer/target_tensor_val.npy',target_tensor_val)\\nnumpy.save(checkpoint_path + 'Tokenizer/input_tensor.npy',input_tensor)\\nnumpy.save(checkpoint_path + 'Tokenizer/target_tensor.npy',target_tensor)\\nwith open(checkpoint_path +  'Tokenizer/inp_lang.pickle', 'wb') as handle:\\n    pickle.dump(inp_lang, handle, protocol=pickle.HIGHEST_PROTOCOL)\\nwith open(checkpoint_path + 'Tokenizer/targ_lang.pickle', 'wb') as handle:\\n    pickle.dump(targ_lang, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHue9OrsqzdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2017e32-084f-4a56-998c-88298920dcbf"
      },
      "source": [
        "# ターゲットテンソルの最大長を計算\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "# 長さを表示\n",
        "print(max_length_targ, max_length_inp)\n",
        "def convert(lang, tensor):\n",
        "    for t in tensor:\n",
        "        if t!=0:\n",
        "            print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "print (\"入力言語;単語マッピングへのインデックス\")\n",
        "convert(inp_lang, input_tensor_train[120])\n",
        "print ()\n",
        "print (\"対象言語;単語マッピングへのインデックス\")\n",
        "convert(targ_lang, target_tensor_train[120])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60 50\n",
            "入力言語;単語マッピングへのインデックス\n",
            "1 ----> <start>\n",
            "5 ----> i\n",
            "103 ----> am\n",
            "109 ----> really\n",
            "1372 ----> pleased\n",
            "36 ----> with\n",
            "19 ----> my\n",
            "142 ----> new\n",
            "113 ----> car\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "対象言語;単語マッピングへのインデックス\n",
            "1 ----> <start>\n",
            "15 ----> 私\n",
            "4 ----> は\n",
            "1743 ----> 新車\n",
            "10 ----> が\n",
            "88 ----> とても\n",
            "907 ----> 気に入っ\n",
            "9 ----> て\n",
            "26 ----> いる\n",
            "3 ----> 。\n",
            "2 ----> <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### tf.data データセットの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqHsArVZ3jFS"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 2\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index) + 1\n",
        "vocab_tar_size = len(targ_lang.word_index) + 1\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## エンコーダー・デコーダーモデルの記述\n",
        "\n",
        "TensorFlow の [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt) に記載されているアテンション付きのエンコーダー・デコーダーモデルを実装します。この例では、最新の API セットを使用します。このノートブックは、上記の seq2seq チュートリアルにある [attention equations](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism) を実装します。下図は、入力の単語ひとつひとつにアテンション機構によって重みが割り当てられ、それを使ってデコーダーが文中の次の単語を予測することを示しています。下記の図と式は [Luong の論文](https://arxiv.org/abs/1508.04025v5) にあるアテンション機構の例です。\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
        "\n",
        "入力がエンコーダーを通過すると、shape が *(batch_size, max_length, hidden_size)* のエンコーダー出力と、shape が *(batch_size, hidden_size)* のエンコーダーの隠れ状態が得られます。\n",
        "\n",
        "下記に実装されている式を示します。\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
        "\n",
        "このチュートリアルでは、エンコーダーでは [Bahdanau attention](https://arxiv.org/pdf/1409.0473.pdf) を使用します。簡略化した式を書く前に、表記方法を定めましょう。\n",
        "\n",
        "* FC = 全結合 (Dense) レイヤー\n",
        "* EO = エンコーダーの出力\n",
        "* H = 隠れ状態\n",
        "* X = デコーダーへの入力\n",
        "\n",
        "\n",
        "擬似コードは下記のとおりです。\n",
        "\n",
        "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
        "* `attention weights = softmax(score, axis = 1)`　softmax は既定では最後の軸に対して実行されますが、スコアの shape が *(batch_size, max_length, hidden_size)*　であるため、*最初の軸* に適用します。`max_length` は入力の長さです。入力それぞれに重みを割り当てようとしているので、softmax はその軸に適用されなければなりません。\n",
        "* `context vector = sum(attention weights * EO, axis = 1)`. 上記と同様の理由で axis = 1 に設定しています。\n",
        "* `embedding output` = デコーダーへの入力 X は Embedding レイヤーを通して渡されます。\n",
        "* `merged vector = concat(embedding output, context vector)`\n",
        "* この結合されたベクトルがつぎに GRU に渡されます。\n",
        "\n",
        "それぞれのステップでのベクトルの shape は、コードのコメントに指定されています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYbwPjLUqeoW"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        return output, state\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))\n",
        "    def restore_from_checkpoint(self):\n",
        "        return tf.train.Checkpoint(tf.train.latest_checkpoint(checkpoint_path))\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # スコアを計算するためにこのように加算を実行する\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # スコアを self.V に適用するために最後の軸は 1 となる\n",
        "    # self.V に適用する前のテンソルの shape は  (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "    # attention_weights の shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    # context_vector の合計後の shape == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    return context_vector, attention_weights\n",
        "attention_layer = BahdanauAttention(10)\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    # アテンションのため\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output の shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "    # 埋め込み層を通過したあとの x の shape  == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "    # 結合後の x の shape == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "    # 結合したベクトルを GRU 層に渡す\n",
        "    output, state = self.gru(x)\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "    return x, state, attention_weights\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1R1POFMrT8P"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "## オプティマイザと損失関数の定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMVWzzsfNl4e"
      },
      "source": [
        "## チェックポイント（オブジェクトベースの保存）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtFZ1hsAtBPx"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igie9X3OOpW6"
      },
      "source": [
        "# オプティマイザと損失関数、チェックポイントの定義\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,encoder=encoder,decoder=decoder)\n",
        "manager = tf.train.CheckpointManager(checkpoint, directory=checkpoint_path, max_to_keep=5)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpObfY22IddU"
      },
      "source": [
        "## 訓練\n",
        "\n",
        "1. *入力* を *エンコーダー* に通すと、*エンコーダー出力* と *エンコーダーの隠れ状態* が返される\n",
        "2. エンコーダーの出力とエンコーダーの隠れ状態、そしてデコーダーの入力（これが *開始トークン*）がデコーダーに渡される\n",
        "3. デコーダーは *予測値* と *デコーダーの隠れ状態* を返す\n",
        "4. つぎにデコーダーの隠れ状態がモデルに戻され、予測値が損失関数の計算に使用される\n",
        "5. デコーダーへの次の入力を決定するために *Teacher Forcing* が使用される\n",
        "6. *Teacher Forcing* は、*正解単語* をデコーダーの *次の入力* として使用するテクニックである\n",
        "7. 最後に勾配を計算し、それをオプティマイザに与えて誤差逆伝播を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddefjBMa3jF0"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "        # Teacher Forcing - 正解値を次の入力として供給\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            # Teacher Forcing を使用\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Translation(EPOCHS,continue_training=False):\n",
        "    Restored = False\n",
        "    if continue_training is True and Restored is False:\n",
        "        checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
        "    for epoch in range(EPOCHS):\n",
        "        start = time.time()\n",
        "        enc_hidden = encoder.initialize_hidden_state()\n",
        "        total_loss = 0\n",
        "        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "            batch_loss = train_step(inp, targ, enc_hidden)\n",
        "            total_loss += batch_loss\n",
        "            if batch % 100 == 0:\n",
        "                print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "        #１エポックごとにモデル（のチェックポイント）を保存\n",
        "        checkpoint.save(checkpoint_path + 'training_checkpoints')\n",
        "        print('\\rEpoch {} Loss {:.4f}'.format(epoch + 1,(total_loss / steps_per_epoch), end=''))\n",
        "        print('\\n' + '1エポックにかかった時間 {} 秒\\n'.format(time.time() - start))\n",
        "        print(\"終了までの予想時間：{} 分\\n\".format(((time.time() - start)*(EPOCHS - (epoch + 1)))/60))"
      ],
      "metadata": {
        "id": "q8gtBWUGXzME"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOANhsrgQaKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d419980-fd15-430b-d185-f6d7ab9caaeb"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f4953da1790>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnv4Iq1I255O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed7648b-5ab7-4576-c0da-d5abec740bc9"
      },
      "source": [
        "Train_Translation(1,True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 1.2093\n",
            "Epoch 1 Batch 100 Loss 0.4354\n",
            "Epoch 1 Batch 200 Loss 0.3447\n",
            "Epoch 1 Batch 300 Loss 0.9636\n",
            "Epoch 1 Batch 400 Loss 0.5006\n",
            "Epoch 1 Batch 500 Loss 0.5103\n",
            "Epoch 1 Batch 600 Loss 0.6460\n",
            "Epoch 1 Batch 700 Loss 0.5160\n",
            "Epoch 1 Batch 800 Loss 0.5220\n",
            "Epoch 1 Batch 900 Loss 0.3966\n",
            "Epoch 1 Batch 1000 Loss 0.3654\n",
            "Epoch 1 Batch 1100 Loss 0.4591\n",
            "Epoch 1 Batch 1200 Loss 0.5266\n",
            "Epoch 1 Batch 1300 Loss 0.9375\n",
            "Epoch 1 Batch 1400 Loss 0.8620\n",
            "Epoch 1 Batch 1500 Loss 0.5728\n",
            "Epoch 1 Batch 1600 Loss 0.6885\n",
            "Epoch 1 Batch 1700 Loss 0.5181\n",
            "Epoch 1 Batch 1800 Loss 0.6846\n",
            "Epoch 1 Batch 1900 Loss 0.3858\n",
            "Epoch 1 Batch 2000 Loss 0.1813\n",
            "Epoch 1 Batch 2100 Loss 0.2992\n",
            "Epoch 1 Batch 2200 Loss 0.5567\n",
            "Epoch 1 Batch 2300 Loss 0.4776\n",
            "Epoch 1 Batch 2400 Loss 0.5709\n",
            "Epoch 1 Batch 2500 Loss 0.4842\n",
            "Epoch 1 Batch 2600 Loss 0.7684\n",
            "Epoch 1 Batch 2700 Loss 0.6024\n",
            "Epoch 1 Batch 2800 Loss 0.2539\n",
            "Epoch 1 Batch 2900 Loss 0.4032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbQpyYs13jF_"
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        # 後ほどプロットするためにアテンションの重みを保存\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        # 予測された ID がモデルに戻される\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence, attention_plot\n",
        "# アテンションの重みをプロットする関数\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    #matplotlib.rcParams['font.family'] = \"IPAGothic\"\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 14}\n",
        "    jp_font = {'fontname':'IPAGothic'}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90, **jp_font)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, **jp_font)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "    print('入力文: %s' % (sentence))\n",
        "    translated = result.replace(' ','')\n",
        "    translated = translated.replace('<end>','')\n",
        "    translated = translated.replace('<start>','')\n",
        "    print('予測される翻訳: {}'.format(translated))\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "## 翻訳\n",
        "\n",
        "* 評価関数は、*Teacher Forcing* を使わないことを除いては、訓練ループと同様である。\n",
        "*タイムステップごとのデコーダーへの入力は、過去の予測値に加えて、隠れ状態とエンコーダーのアウトプットである。\n",
        "* モデルが終了トークンを予測したら、予測を停止する。\n",
        "* また、タイムステップごとのアテンションの重みを保存する。\n",
        "\n",
        "Note: エンコーダーの出力は 1 つの入力に対して 1 回だけ計算されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n250XbnjOaqP"
      },
      "source": [
        "## 最後のチェックポイントを復元しテストする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrAM0FDomq3E"
      },
      "source": [
        "translate('It is very cold here.')\n",
        "translate('This is my life.')\n",
        "translate('Are you still at home?')\n",
        "translate('My work time for the last three months.')\n",
        "translate(u'I made an appointment to see the doctor at four o\\'clock.')\n",
        "translate('Can you imagine what the 21st century will be like?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSx2iM36EZQZ"
      },
      "source": [
        "translate('This is my life.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3LLCx3ZE0Ls"
      },
      "source": [
        "translate('Are you still at home?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUQVLVqUE1YW"
      },
      "source": [
        "translate('The journey of life will continue.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZmKogGqji_V"
      },
      "source": [
        "translate('I made an appointment to see the doctor at four o\\'clock.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSN2EAfKkRxR"
      },
      "source": [
        "translate('Can you imagine?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTe5P5ioMJwN"
      },
      "source": [
        "## 次のステップ\n",
        "\n",
        "* [異なるデータセットをダウンロード](http://www.manythings.org/anki/)して翻訳の実験を行ってみよう。たとえば英語からドイツ語や、英語からフランス語。\n",
        "* もっと大きなデータセットで訓練を行ったり、もっと多くのエポックで訓練を行ったりしてみよう。"
      ]
    }
  ]
}